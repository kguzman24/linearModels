{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "e0c7b14a-e5aa-4abc-b48b-b8a9d20dacac",
      "metadata": {
        "id": "e0c7b14a-e5aa-4abc-b48b-b8a9d20dacac"
      },
      "source": [
        "# Assignment: Linear Models\n",
        "## Do three questions.\n",
        "### `! git clone https://github.com/ds4e/linearModels`"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf4826b0",
      "metadata": {
        "id": "bf4826b0"
      },
      "source": [
        "**Q1.** Please answer the following questions in your own words.\n",
        "\n",
        "1. What makes a model \"linear\"? \"Linear\" in what?\n",
        "2. How do you interpret the coefficient for a dummy/one-hot-encoded variable? (This is a trick question, and the trick involves how you handle the intercept of the model.)\n",
        "3. Can linear regression be used for classification? Explain why, or why not.\n",
        "4. What are signs that your linear model is over-fitting?\n",
        "5. Clearly explain multi-colinearity using the two-stage least squares technique.\n",
        "6. How can you incorporate nonlinear relationships between your target/response/dependent/outcome variable $y$ and your features/control/response/independent variables $x$ into your analysis?\n",
        "7. What is the interpretation of the intercept? A slope coefficient for a variable? The coefficient for a dummy/one-hot-encoded variable?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "44fbab01",
      "metadata": {},
      "source": [
        "1. A model is \"linear\" when it uses explanatory variables (x) to predict the outcome variable (y). This means that Y can be expressed as a linear combination of the explanatory variables; it's linear in coefficients.\n",
        "2. The coefficient for a dummy variable in dummy encoding with an intercept can be interpreted as a deviation from a chosen reference category. If the color purple is the reference category, the coefficient of beta_1 for a dummy variable of green would be the difference in Y between green and the reference category purple. The coefficients are basically deviations from reference categories. In one-hot encoding without an intercept, we create separate dummy variables for each category and drop the intercept to avoid perfect multicolinearity. This means that the coefficients represent the expected value of Y for that category, not a difference from reference category. If you are interpreting the coefficients, your decision of dropping the intercept or not matters. \n",
        "3. Linear regression can be used for classification because it weights the explanatory variables to predict the outcome variables but it should be used with caution. For example, predictions with linear regression may lead to predictions that are out of range because it assumes continuous output. There are better linear models that are better than others for classification. \n",
        "4. Some signs would include that the model itself seems too complicated with too many features. If we are using too many variables that exploit unique features of the training data, we may overfit out model. Another sign is if out model performs well with out training data but has a lot more error with our test data. This would mean that the model is too complex and is fitting to the training set too closely rather than general patterns.\n",
        "5. Multicollinearity occurs when two or more predictor variables are highly correlated. This means that they provide redundant information. This makes it difficult to differentiate the individual effect of each predictor on Y. In two stage least squares, the first stage consists of identifying variables that are correlated with the ones causing multicollinearity (these are endogenuous variables) but not correlated with the error term. You then regresss the endogenous variables to get predicted values for them. In stage two, you use the predicted values you got and use them as independent variables in your regression model. This will remove the multicollinearity.\n",
        "6. You can incorporate non linear relationships using neural networks since they are nests of linear models. You can also use more complex polynomial terms like squares, cubes, etc. You could also incorporate logs and exponential transformations.\n",
        "7. The interpretations of the intercept is the predicted value of Y when all the independent variables are 0. The slope coefficient for a variable is the change in the predicted value of Y for a unit increase of the X variable. The interpretation for a slope coefficient for a dummy variable represents the difference in y when the category that the dummy variable represents is present (coefficient of 1) or absent (coefficient of 0)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25bf83c6-ff44-42d6-9b33-8be1b945860d",
      "metadata": {
        "id": "25bf83c6-ff44-42d6-9b33-8be1b945860d"
      },
      "source": [
        "**Q2.** Load `./data/Q1_clean.csv`. The data include\n",
        "\n",
        "- `Price` per night\n",
        "- `Review Scores Rating`: The average rating for the property\n",
        "- `Neighbourhood `: The bourough of NYC. Note the space, or rename the variable.\n",
        "- `Property Type`: The kind of dwelling\n",
        "- `Room Type`: The kind of space being rented\n",
        "\n",
        "1. Compute the average prices and scores by `Neighbourhood `; which bourough is the most expensive on average? Create a kernel density plot of price and log price, grouping by `Neighbourhood `.\n",
        "2. Regress price on `Neighbourhood ` by creating the appropriate dummy/one-hot-encoded variables, without an intercept in the linear model and using all the data. Compare the coefficients in the regression to the table from part 1. What pattern do you see? What are the coefficients in a regression of a continuous variable on one categorical variable?\n",
        "3. Repeat part 2, but leave an intercept in the linear model. How do you have to handle the creation of the dummies differently? What is the intercept? Interpret the coefficients. How can I get the coefficients in part 2 from these new coefficients?\n",
        "4. Split the sample 80/20 into a training and a test set. Run a regression of `Price` on `Review Scores Rating` and `Neighbourhood `. What is the $R^2$ and RMSE on the test set? What is the coefficient on `Review Scores Rating`? What is the most expensive kind of property you can rent?\n",
        "5. Split the sample 80/20 into a training and a test set. Run a regression of `Price` on `Review Scores Rating` and `Neighbourhood ` and `Property Type`. What is the $R^2$ and RMSE on the test set? What is the coefficient on `Review Scores Rating`? What is the most expensive kind of property you can rent?\n",
        "6. What does the coefficient on `Review Scores Rating` mean if it changes from part 4 to 5? Hint: Think about how multilple linear regression works.\n",
        "7. (Optional) We've included `Neighborhood ` and `Property Type` separately in the model. How do you interact them, so you can have \"A bedroom in Queens\" or \"A townhouse in Manhattan\". Split the sample 80/20 into a training and a test set and run a regression including that kind of \"property type X neighborhood\" dummy, plus `Review Scores Rating`. How does the slope coefficient for `Review Scores Rating`, the $R^2$, and the RMSE change? Do they increase significantly compares to part 5? Are the coefficients in this regression just the sum of the coefficients for `Neighbourhood ` and `Property Type` from 5? What is the most expensive kind of property you can rent?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95f22300-0180-4ed2-be8f-ed56cf4cd36b",
      "metadata": {
        "id": "95f22300-0180-4ed2-be8f-ed56cf4cd36b"
      },
      "source": [
        "**Q3.** This question is a case study for linear models. The data are about car prices. In particular, they include:\n",
        "\n",
        "  - `Price`, `Color`, `Seating_Capacity`\n",
        "  - `Body_Type`: crossover, hatchback, muv, sedan, suv\n",
        "  - `Make`, `Make_Year`: The brand of car and year produced\n",
        "  - `Mileage_Run`: The number of miles on the odometer\n",
        "  - `Fuel_Type`: Diesel or gasoline/petrol\n",
        "  - `Transmission`, `Transmission_Type`:  speeds and automatic/manual\n",
        "\n",
        "  1. Load `cars_hw.csv`. These data were really dirty, and I've already cleaned them a significant amount in terms of missing values and other issues, but some issues remain (e.g. outliers, badly scaled variables that require a log or arcsinh transformation). Clean the data however you think is most appropriate.\n",
        "  2. Summarize the `Price` variable and create a kernel density plot. Use `.groupby()` and `.describe()` to summarize prices by brand (`Make`). Make a grouped kernel density plot by `Make`. Which car brands are the most expensive? What do prices look like in general?\n",
        "  3. Split the data into an 80% training set and a 20% testing set.\n",
        "  4. Make a model where you regress price on the numeric variables alone; what is the $R^2$ and `RMSE` on the training set and test set? Make a second model where, for the categorical variables, you regress price on a model comprised of one-hot encoded regressors/features alone (you can use `pd.get_dummies()`; be careful of the dummy variable trap); what is the $R^2$ and `RMSE` on the test set? Which model performs better on the test set? Make a third model that combines all the regressors from the previous two; what is the $R^2$ and `RMSE` on the test set? Does the joint model perform better or worse, and by home much?\n",
        "  5. Use the `PolynomialFeatures` function from `sklearn` to expand the set of numerical variables you're using in the regression. As you increase the degree of the expansion, how do the $R^2$ and `RMSE` change? At what point does $R^2$ go negative on the test set? For your best model with expanded features, what is the $R^2$ and `RMSE`? How does it compare to your best model from part 4?\n",
        "  6. For your best model so far, determine the predicted values for the test data and plot them against the true values. Do the predicted values and true values roughly line up along the diagonal, or not? Compute the residuals/errors for the test data and create a kernel density plot. Do the residuals look roughly bell-shaped around zero? Evaluate the strengths and weaknesses of your model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aedcd486",
      "metadata": {},
      "source": [
        "**Q4.** This question refers to the `heart_hw.csv` data. It contains three variables:\n",
        "\n",
        "  - `y`: Whether the individual survived for three years, coded 0 for death and 1 for survival\n",
        "  - `age`: Patient's age\n",
        "  - `transplant`: `control` for not receiving a transplant and `treatment` for receiving a transplant\n",
        "\n",
        "Since a heart transplant is a dangerous operation and even people who successfully get heart transplants might suffer later complications, we want to look at whether a group of transplant recipients tends to survive longer than a comparison group who does not get the procedure.\n",
        "\n",
        "1. Compute (a) the proportion of people who survive in the control group who do not receive a transplant, and (b) the difference between the proportion of people who survive in the treatment group and the proportion of people who survive in the control group. In a randomized controlled trial, this is called the **average treatment effect**.\n",
        "2. Regress `y` on `transplant` using a linear model with a constant. How does the constant/intercept of the regression and the coefficient on transplant compare to your answers from part 1? Explain the relationship clearly.\n",
        "3. We'd like to include `age` in the regression, since it's reasonable to expect that older patients are less likely to survive an extensive surgery like a heart transplant. Regress `y` on a constant, transplant, and age. How does the intercept change?\n",
        "4. Build a more flexible model that allows for non-linear age effects and interactions between age and treatment. Use a train-test split to validate your model. Estimate your best model, predict the survival probability by age, and plot your results conditional on receiving a transplant and not. Describe what you see.\n",
        "5. Imagine someone suggests using these kinds of models to select who receives organ transplants; perhaps the CDC or NIH starts using a scoring algorithm to decide who is contacted about a potential organ. What are your concerns about how it is built and how it is deployed?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97e443e6",
      "metadata": {},
      "source": [
        "#### 4.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8ed9a0cb",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "844a7c02",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of      Unnamed: 0  age transplant  y\n",
              "0             1   53    control  0\n",
              "1             2   43    control  0\n",
              "2             3   52    control  0\n",
              "3             4   52    control  0\n",
              "4             5   54    control  0\n",
              "..          ...  ...        ... ..\n",
              "98           99   30    control  1\n",
              "99          100   48  treatment  1\n",
              "100         101   40  treatment  1\n",
              "101         102   48  treatment  1\n",
              "102         103   33  treatment  1\n",
              "\n",
              "[103 rows x 4 columns]>"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "heart_data = pd.read_csv(\"data/heart_hw.csv\")\n",
        "heart_data.head"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "026fb739",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Control group: 0.11764705882352941\n",
            "Treatment group: 0.34782608695652173\n",
            "fAverage treatment effect: 0.23017902813299232\n"
          ]
        }
      ],
      "source": [
        "control_group = heart_data[heart_data['transplant']=='control']\n",
        "treatment_group = heart_data[heart_data['transplant']=='treatment']\n",
        "\n",
        "#proportion of survivors in control\n",
        "control_survival = control_group['y'].mean()\n",
        "\n",
        "#proportion of survivors in treatment\n",
        "treatment_survival = treatment_group['y'].mean()\n",
        "\n",
        "average_treatment_effect = treatment_survival-control_survival\n",
        "\n",
        "print(f\"Control group: {control_survival}\")\n",
        "print(f\"Treatment group: {treatment_survival}\")\n",
        "print(f\"fAverage treatment effect: {average_treatment_effect}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9345e8b5",
      "metadata": {},
      "source": [
        "#### 4.2 "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "32f58232",
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def slr(x,y): \n",
        "    \"\"\" Single linear regression function. \"\"\"\n",
        "    x_bar = np.mean(x)\n",
        "    y_bar = np.mean(y)\n",
        "\n",
        "    denominator = np.inner(x - x_bar, x - x_bar)\n",
        "    if denominator == 0:\n",
        "        return {'b0': np.nan, 'b1': np.nan, 'y_hat': np.nan, 'residuals': np.nan}\n",
        "    \n",
        "    b1 = np.inner(x-x_bar,y-y_bar)/denominator\n",
        "    b0 = y_bar - b1*x_bar\n",
        "    y_hat = b0 + b1*x\n",
        "    residuals = y - y_hat\n",
        "    return({'b0':b0,'b1':b1,'y_hat':y_hat,'residuals':residuals})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "4a38e8cf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transplant coefficient:  0.23017902813299226\n",
            "Intercept:  0.11764705882352944\n"
          ]
        }
      ],
      "source": [
        "#print(heart_data['transplant'])\n",
        "heart_data = pd.read_csv(\"data/heart_hw.csv\")\n",
        "\n",
        "\n",
        "heart_data['transplant'] = heart_data['transplant'].apply(lambda x: 1 if x == 'treatment' else 0)\n",
        "\n",
        "\n",
        "y = heart_data['y']\n",
        "x1 = heart_data['transplant']\n",
        "#print(heart_data['transplant'])\n",
        "\n",
        "reg1_y = slr(x1,y) # Regress y on x1\n",
        "#print(reg1_y)\n",
        "transplant_coeff = reg1_y['b1'] #coefficient for tranplant\n",
        "\n",
        "intercept =  reg1_y['b0'] #intercept\n",
        "\n",
        "print('Transplant coefficient: ', transplant_coeff)\n",
        "print('Intercept: ', intercept)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c6494fe",
      "metadata": {},
      "source": [
        "In our linear regression model, the intercept is 0.7, which is the proportion of people who survive in the control group. The transplant coefficient represents the difference in survival probability between the treatment and control group. This number means that patients have a 1.18% higher survival probability than those who did not receive the transplant. In part 1, the rate of survival for the control group was 0.1176. For the transplant coefficient in part 1 was 0.2302 and was 0.2301 in the regression model. Both of these values are close, which means that the regression model is doing a good job at showing the true relationship between transplant and survival."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ac5ff8a6",
      "metadata": {},
      "source": [
        "#### 4.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "b5a53467",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Age coefficient: -0.013607217160218645\n",
            "Transplant coefficient: 0.264701686503675\n",
            "Intercept:  0.6322211923403473 \n",
            "\n"
          ]
        }
      ],
      "source": [
        "heart_data = pd.read_csv(\"data/heart_hw.csv\")\n",
        "\n",
        "heart_data['transplant'] = heart_data['transplant'].apply(lambda x: 1 if x == 'treatment' else 0)\n",
        "\n",
        "\n",
        "y = heart_data['y']\n",
        "x1 = heart_data['transplant']\n",
        "x2 = heart_data['age']\n",
        "\n",
        "#get resid for y after regress on x1\n",
        "reg1_y = slr(x1,y) # Regress y on x1\n",
        "y_resid_x1 = reg1_y['residuals'] # Extract the residual for y\n",
        "\n",
        "#get resid for x2 after regressing on x1\n",
        "reg_x2_x1 = slr(x1, x2)\n",
        "x2_resid_x1 = reg_x2_x1['residuals']\n",
        "\n",
        "#regress to et age coeff\n",
        "reg_y_x2 = slr(x2_resid_x1, y_resid_x1)\n",
        "age_coeff = reg_y_x2['b1']\n",
        "print('Age coefficient:', age_coeff)\n",
        "\n",
        "#get resid for y after regres on x2\n",
        "reg_y_x2 = slr(x2, y)\n",
        "y_resid_x2 = reg_y_x2['residuals']\n",
        "\n",
        "#get regress for x1 after regress on x2\n",
        "reg_x1_x2 = slr(x2, x1)\n",
        "x1_resid_x2 = reg_x1_x2['residuals']\n",
        "\n",
        "#regress to get transplant coeff\n",
        "reg_y_x1 = slr(x1_resid_x2, y_resid_x2)\n",
        "transplant_coeff = reg_y_x1['b1']\n",
        "print('Transplant coefficient:', transplant_coeff)\n",
        "\n",
        "\n",
        "b0 = np.mean(y) - reg_y_x1['b1'] * np.mean(x1) - reg_y_x2['b1']*np.mean(x2)\n",
        "print('Intercept: ', b0, '\\n')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97b611d7",
      "metadata": {},
      "source": [
        "The intercept changes to 0.632. This means that the baseline probabiliy of survival for the control group has decreased."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9ff5ab92",
      "metadata": {},
      "source": [
        "#### 4.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "id": "69f6004f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Defaulting to user installation because normal site-packages is not writeable\n",
            "Collecting statsmodels\n",
            "  Downloading statsmodels-0.14.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=21.3 in /home/karenguzman/.local/lib/python3.10/site-packages (from statsmodels) (24.1)\n",
            "Requirement already satisfied: scipy!=1.9.2,>=1.8 in /home/karenguzman/.local/lib/python3.10/site-packages (from statsmodels) (1.14.1)\n",
            "Requirement already satisfied: numpy<3,>=1.22.3 in /home/karenguzman/.local/lib/python3.10/site-packages (from statsmodels) (2.0.2)\n",
            "Collecting patsy>=0.5.6\n",
            "  Downloading patsy-1.0.1-py2.py3-none-any.whl (232 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.9/232.9 KB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas!=2.1.0,>=1.4 in /home/karenguzman/.local/lib/python3.10/site-packages (from statsmodels) (2.2.3)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /home/karenguzman/.local/lib/python3.10/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/karenguzman/.local/lib/python3.10/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2024.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/karenguzman/.local/lib/python3.10/site-packages (from pandas!=2.1.0,>=1.4->statsmodels) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas!=2.1.0,>=1.4->statsmodels) (1.16.0)\n",
            "Installing collected packages: patsy, statsmodels\n",
            "Successfully installed patsy-1.0.1 statsmodels-0.14.4\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install statsmodels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "id": "71a3ace4",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Optimization terminated successfully.\n",
            "         Current function value: 0.513893\n",
            "         Iterations 7\n",
            "                           Logit Regression Results                           \n",
            "==============================================================================\n",
            "Dep. Variable:                      y   No. Observations:                   82\n",
            "Model:                          Logit   Df Residuals:                       77\n",
            "Method:                           MLE   Df Model:                            4\n",
            "Date:                Mon, 24 Mar 2025   Pseudo R-squ.:                  0.1499\n",
            "Time:                        12:16:14   Log-Likelihood:                -42.139\n",
            "converged:                       True   LL-Null:                       -49.572\n",
            "Covariance Type:            nonrobust   LLR p-value:                  0.004988\n",
            "==================================================================================\n",
            "                     coef    std err          z      P>|z|      [0.025      0.975]\n",
            "----------------------------------------------------------------------------------\n",
            "const             -1.7967      3.033     -0.592      0.554      -7.741       4.148\n",
            "transplant         2.8479      3.145      0.906      0.365      -3.316       9.012\n",
            "age                0.0870      0.174      0.500      0.617      -0.254       0.428\n",
            "age_squared       -0.0020      0.003     -0.778      0.436      -0.007       0.003\n",
            "age_transplant    -0.0319      0.075     -0.423      0.672      -0.180       0.116\n",
            "==================================================================================\n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import statsmodels.api as sm\n",
        "\n",
        "\n",
        "heart_data = pd.read_csv(\"data/heart_hw.csv\")\n",
        "heart_data['transplant'] = heart_data['transplant'].apply(lambda x: 1 if x == 'treatment' else 0)\n",
        "\n",
        "#adding quadratic age term\n",
        "heart_data['age_squared'] = heart_data['age'] ** 2\n",
        "\n",
        "#adding interaction\n",
        "heart_data['age_transplant'] = heart_data['age'] * heart_data['transplant']\n",
        "\n",
        "#define\n",
        "X = heart_data[['transplant', 'age', 'age_squared', 'age_transplant']]\n",
        "y = heart_data['y']\n",
        "\n",
        "#train test split (80% train, 20% test)\n",
        "X_train, X_test, y_train, y_test = (train_test_split(X, y, test_size=0.2, random_state=41))\n",
        "\n",
        "#fitting a logistic regression model\n",
        "X_train = sm.add_constant(X_train) #adds intercept\n",
        "logit_model = sm.Logit(y_train, X_train).fit()\n",
        "\n",
        "#summary\n",
        "print(logit_model.summary())\n",
        "\n",
        "#survival prob for range of ages\n",
        "ages = np.linspace(heart_data['age'].min(), heart_data['age'].max(), 100)\n",
        "\n",
        "plot_data = pd.DataFrame({\n",
        "    'const': 1,  #intercept\n",
        "    'transplant': np.tile([0, 1], len(ages)),  \n",
        "    'age': np.tile(ages, 2), #age range\n",
        "    'age_squared': np.tile(ages**2, 2),  #our quadtratic term\n",
        "    'age_transplant': np.concatenate([ages * 0, ages * 1])  #our interaction term\n",
        "})\n",
        "\n",
        "#predicting survival probs\n",
        "plot_data['predicted_survival'] = logit_model.predict(plot_data)\n",
        "\n",
        "#plotting\n",
        "plt.plot(ages, plot_data[plot_data['transplant'] == 0]['predicted_survival'], label='No Transplant', color='red')\n",
        "plt.plot(ages, plot_data[plot_data['transplant'] == 1]['predicted_survival'], label='Transplant', color='blue')\n",
        "\n",
        "plt.xlabel('Age')\n",
        "plt.ylabel('Predicted Survival Probability')\n",
        "plt.title('Predicted Survival Probability by Age (With and Without Transplant)')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0aaf01ef",
      "metadata": {},
      "source": [
        "The predicted survival probability is much higher on average with a transplant. Around the age of 35 however, both probabilities with and without the transplant are about 0.20 or less. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e9f58c98",
      "metadata": {},
      "source": [
        "#### 4.5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5aede0d3",
      "metadata": {},
      "source": [
        "My concerns about how it is build would be whether the training data contains biases in it. If it represents past biases, the model would reinforce those biases and lead to discrimination. Also, if age has a negative coefficient, older patients may be unfairly deprioritized. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7bd15c6b-4c7c-4230-a199-e03e1054ec6a",
      "metadata": {
        "id": "7bd15c6b-4c7c-4230-a199-e03e1054ec6a"
      },
      "source": [
        "**Q5.** This is a question about linear regression. The outcome is whether a defendant is held pre-trial in the Virginia justice system. We would like to understand how that outcome is predicted by characteristics of the defendant, particularly race. Let's be very careful/clear: We aren't saying anyone *should* be held without bond or asserting that people with different demographic variables *should* be more likely to be held, but instead trying to predict whether people with different characteristics *are empirically more likely* to be held without bond, given the available information. This is the first step we would take in investigating whether a system is fair, or how large the disparities are: Does it treat people with similar observable characteristics similarly, or not? We are going to look at a common question: Are Black defendants treated differently from white or Asian ones? (There are Native American defendants, but there are 11 in total, which is such a small number of observations that is difficult to clearly say anything about how this group is treated relative to the others.)\n",
        "\n",
        "The variables in the data are:\n",
        "\n",
        "  - `held_wo_bail`: Whether a defendant is held without bail before trial (Boolean logical)\n",
        "  - `race`, `sex`: Categorical demographic variables\n",
        "  - `is_poor`: Whether the defendant is classified as indigent\n",
        "  - `prior_F`, `prior_M`: The number of prior felony and misdemeanor arrests\n",
        "  - `case_type`: A categorical variable indicating a misdemeanor `M` or felony `F` or infraction `I` or special case `S`\n",
        "  - `age`: Defendant's age\n",
        "  - `bond`, `bond_NA`, `bond_type`: The amount of any bond, whether it is missing, and the type\n",
        "  - `sentence`, `sentence_NA`, `sentence_type`: The length of any sentence, whether it is missing, and the type\n",
        "\n",
        "1. Load the `pretrial_data.csv` data. Notice that there are `nan`s, but the data are relatively clean. Because there are `.nan`s among variables you won't use, you'll want to narrow down your analysis to the relevant variables before dropping or imputing missing values.\n",
        "2. Create a dummy variable indicating that the defendant is Black.\n",
        "3. Regress `held` on `Black`. What is the slope coefficient Interpret the coefficient on the Black dummy variable: How much more likely is a black person to be held without bail? What is the $R^2$ of the model?\n",
        "4. Before doing this question, please think for a few minutes about how to make the process of running the following regressions as efficient as possible, before jumping into writing code. Repeat part 2, for the following specifications, keeping track of the coefficient on the Black dummy variable each time:\n",
        "      - `held` on `Black` and `sex`\n",
        "      - `held` on `Black` and `sex` and `is_poor`\n",
        "      - `held` on `Black` and `sex` and `is_poor` and `prior_F`\n",
        "      - `held` on `Black` and `sex` and `is_poor` and `prior_F` and `case_type`\n",
        "What happens to the coefficient on the Black dummy variable as you include more regressors/features/controls in the regression? Explain your findings.\n",
        "5. Suppose we don't want to see just `Black` and `sex`, but `Black` interacted with `sex`: Are Black men and Black women treated systemically differently from the rest of the population? Implement this in a regression, and explain your findings.\n",
        "6. Imagine someone argued we should use these kinds of models to help a judge or magistrate make bail decisions (you could obviously go back and make this kind of model for the bond and sentence variables, then deploy it on new cases to predict what their bond and sentence values would be). What concerns would you have? Do you think society should be using data-driven and automated tools like that? Explain your concerns clearly."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0f2222a4",
      "metadata": {},
      "source": [
        "#### 5.1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "id": "e3811c96",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>race</th>\n",
              "      <th>is_poor</th>\n",
              "      <th>prior_F</th>\n",
              "      <th>case_type</th>\n",
              "      <th>held_wo_bail</th>\n",
              "      <th>sex</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>W</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>F</td>\n",
              "      <td>False</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>B</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13.0</td>\n",
              "      <td>F</td>\n",
              "      <td>False</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>W</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.0</td>\n",
              "      <td>M</td>\n",
              "      <td>False</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>B</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>M</td>\n",
              "      <td>False</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>W</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>F</td>\n",
              "      <td>False</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22981</th>\n",
              "      <td>B</td>\n",
              "      <td>1.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>M</td>\n",
              "      <td>False</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22982</th>\n",
              "      <td>W</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>M</td>\n",
              "      <td>False</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22983</th>\n",
              "      <td>B</td>\n",
              "      <td>1.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>M</td>\n",
              "      <td>False</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22984</th>\n",
              "      <td>B</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>M</td>\n",
              "      <td>False</td>\n",
              "      <td>F</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22985</th>\n",
              "      <td>B</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>M</td>\n",
              "      <td>False</td>\n",
              "      <td>M</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>22986 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      race  is_poor  prior_F case_type  held_wo_bail sex\n",
              "0        W      NaN      0.0         F         False   M\n",
              "1        B      NaN     13.0         F         False   M\n",
              "2        W      NaN      0.0         M         False   M\n",
              "3        B      0.0      0.0         M         False   M\n",
              "4        W      0.0      0.0         F         False   F\n",
              "...    ...      ...      ...       ...           ...  ..\n",
              "22981    B      1.0     12.0         M         False   M\n",
              "22982    W      NaN      NaN         M         False   F\n",
              "22983    B      1.0      6.0         M         False   M\n",
              "22984    B      0.0      1.0         M         False   F\n",
              "22985    B      1.0      2.0         M         False   M\n",
              "\n",
              "[22986 rows x 6 columns]"
            ]
          },
          "execution_count": 109,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "pretrial_data = pd.read_csv(\"data/pretrial_data.csv\")\n",
        "pretrial_data.head\n",
        "\n",
        "subset_pretrial_data = pretrial_data[['race','is_poor','prior_F','case_type', 'held_wo_bail','sex']]\n",
        "subset_pretrial_data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a5b47549",
      "metadata": {},
      "source": [
        "#### 5.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "id": "cb05bba9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0        0\n",
            "1        1\n",
            "2        0\n",
            "3        1\n",
            "4        0\n",
            "        ..\n",
            "22981    1\n",
            "22982    0\n",
            "22983    1\n",
            "22984    1\n",
            "22985    1\n",
            "Name: race_black, Length: 22986, dtype: int64\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_3544/2296720173.py:1: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  subset_pretrial_data['race_black'] = (subset_pretrial_data['race']=='B').astype(int)\n"
          ]
        }
      ],
      "source": [
        "subset_pretrial_data['race_black'] = (subset_pretrial_data['race']=='B').astype(int)\n",
        "print(subset_pretrial_data['race_black'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "06e0312a",
      "metadata": {},
      "source": [
        "#### 5.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "id": "7bc034d7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                            OLS Regression Results                            \n",
            "==============================================================================\n",
            "Dep. Variable:           held_wo_bail   R-squared:                       0.007\n",
            "Model:                            OLS   Adj. R-squared:                  0.007\n",
            "Method:                 Least Squares   F-statistic:                     154.0\n",
            "Date:                Mon, 24 Mar 2025   Prob (F-statistic):           3.03e-35\n",
            "Time:                        13:00:01   Log-Likelihood:                -13567.\n",
            "No. Observations:               22986   AIC:                         2.714e+04\n",
            "Df Residuals:                   22984   BIC:                         2.715e+04\n",
            "Df Model:                           1                                         \n",
            "Covariance Type:            nonrobust                                         \n",
            "==============================================================================\n",
            "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
            "------------------------------------------------------------------------------\n",
            "const          0.2295      0.004     61.493      0.000       0.222       0.237\n",
            "race_black     0.0728      0.006     12.409      0.000       0.061       0.084\n",
            "==============================================================================\n",
            "Omnibus:                     4842.763   Durbin-Watson:                   1.646\n",
            "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5127.594\n",
            "Skew:                           1.090   Prob(JB):                         0.00\n",
            "Kurtosis:                       2.223   Cond. No.                         2.45\n",
            "==============================================================================\n",
            "\n",
            "Notes:\n",
            "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
          ]
        }
      ],
      "source": [
        "#print(pretrial_data['race_black'])\n",
        "\n",
        "y=subset_pretrial_data['held_wo_bail']\n",
        "\n",
        "X=subset_pretrial_data['race_black']\n",
        "\n",
        "X=sm.add_constant(X) #adding intercept\n",
        "\n",
        "#running the regression (in this case OLS)\n",
        "model= sm.OLS(y,X).fit()\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7907b6e6",
      "metadata": {},
      "source": [
        "The slope coefficient for race_black is 0.0728. This means that there is 7.28% higher chance that a black person is held without bail. The R^2 of the model is 0.007. This means that only 0.7% of the variation in whether someone is held without bail is explained by the model."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7caf9ba",
      "metadata": {},
      "source": [
        "#### 5.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "id": "a32cb568",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                      Variables  Coef (Black)       R^2\n",
            "0                                    race_black      0.068436  0.005819\n",
            "1                               race_black, sex      0.063120  0.016260\n",
            "2                      race_black, sex, is_poor      0.036318  0.059278\n",
            "3             race_black, sex, is_poor, prior_F      0.026586  0.100833\n",
            "4  race_black, sex, is_poor, prior_F, case_type      0.028455  0.196171\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_3544/3052417446.py:2: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  subset_pretrial_data['race_black'] = (subset_pretrial_data['race']=='B').astype(int)\n",
            "/tmp/ipykernel_3544/3052417446.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  subset_pretrial_data['sex'] = subset_pretrial_data['sex'].astype('category').cat.codes\n",
            "/tmp/ipykernel_3544/3052417446.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  subset_pretrial_data['race'] = subset_pretrial_data['race'].astype('category').cat.codes\n",
            "/tmp/ipykernel_3544/3052417446.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  subset_pretrial_data['case_type'] = subset_pretrial_data['case_type'].astype('category').cat.codes\n"
          ]
        }
      ],
      "source": [
        "subset_pretrial_data = pretrial_data[['race','is_poor','prior_F','case_type', 'held_wo_bail','sex']]\n",
        "subset_pretrial_data['race_black'] = (subset_pretrial_data['race']=='B').astype(int)\n",
        "subset_pretrial_data['sex'] = subset_pretrial_data['sex'].astype('category').cat.codes\n",
        "subset_pretrial_data['race'] = subset_pretrial_data['race'].astype('category').cat.codes\n",
        "subset_pretrial_data['case_type'] = subset_pretrial_data['case_type'].astype('category').cat.codes\n",
        "subset_pretrial_data = subset_pretrial_data.dropna()\n",
        "\n",
        "\n",
        "\n",
        "#print(subset_pretrial_data.dtypes)\n",
        "\n",
        "case_type_dummies = [col for col in subset_pretrial_data.columns if col.startswith(\"case_type\")]\n",
        "\n",
        "y=subset_pretrial_data['held_wo_bail']\n",
        "y = np.asarray(y)\n",
        "\n",
        "\n",
        "set = [\n",
        "    ['race_black'],\n",
        "    ['race_black', 'sex'],\n",
        "    ['race_black', 'sex', 'is_poor'],\n",
        "    ['race_black', 'sex', 'is_poor', 'prior_F'],\n",
        "    ['race_black', 'sex', 'is_poor', 'prior_F'] +case_type_dummies\n",
        "]\n",
        "\n",
        "\n",
        "results = []\n",
        "\n",
        "for variables in set:\n",
        "    X=subset_pretrial_data[variables]\n",
        "    X = sm.add_constant(X, has_constant='add') #adding intercept\n",
        "\n",
        "\n",
        "    #running the regression (in this case OLS)\n",
        "\n",
        "    model= sm.OLS(y,X).fit()\n",
        "\n",
        "    #getting stats\n",
        "    coef_black = model.params.get('race_black', None)\n",
        "    r_squared = model.rsquared\n",
        "\n",
        "    #adding to results\n",
        "    results.append({\n",
        "        'Variables': ', '.join(variables),\n",
        "        'Coef (Black)': coef_black,\n",
        "        'R^2': r_squared\n",
        "    })\n",
        "\n",
        "results_df=pd.DataFrame(results)\n",
        "print(results_df)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "657db46d",
      "metadata": {},
      "source": [
        "As more variables are added, the coefficient for race_black decreases and the R^2 increases. The race coefficient suggests that the effect of race becomes less pronounced when accounting for other features and th2 R^2 suggests that the overall model gets better at explaining outcomes with more predictors."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f1432b18",
      "metadata": {},
      "source": [
        "#### 5.5"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "03e52be4",
      "metadata": {},
      "source": [
        " Suppose we don't want to see just `Black` and `sex`, but `Black` interacted with `sex`: Are Black men and Black women treated systemically differently from the rest of the population? Implement this in a regression, and explain your findings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "id": "4643ef90",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Coefficient: 0.05133252310900626,\n",
            "R squared: 0.011114555183757813\n"
          ]
        }
      ],
      "source": [
        "subset_pretrial_data['race_black_sex']= subset_pretrial_data['race_black']* subset_pretrial_data['sex']\n",
        "\n",
        "X = subset_pretrial_data['race_black_sex']\n",
        "X = sm.add_constant(X, has_constant='add')  # Add intercept\n",
        "\n",
        "model = sm.OLS(y, X).fit()\n",
        "coef_race_black_sex = model.params['race_black_sex']\n",
        "r_squared = model.rsquared\n",
        "\n",
        "print(f'Coefficient: {coef_race_black_sex},\\nR squared: {r_squared}')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2197310d",
      "metadata": {},
      "source": [
        "The coefficient measures the effect of being black and a specific gender on the dependent variable of being held without bail. This suggest that the group is 5.1% more likelt to be held with no bail compared to others. The R^2 suggests that 1.1% of the variation in held without bail varianle is explained soley by the interaction term."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9bb4ca2f",
      "metadata": {},
      "source": [
        "#### 5.6"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66061ad4",
      "metadata": {},
      "source": [
        "Data-driven and automated tools like this regression model has the potential to enhance efficiency and consistency in decision-making, but there are significant concerns. These are high-stake decisions that need context. There could be bias if the models rely on biased or discriminatory data. This appraoch could use and reinforce systemic discrimination. There are also concerns about each case not being a \"standard\" case; in other words, every person's case is individual and complex human situations should not be simplified to patterns or strict probabilities."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca1cfba3",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "\n",
        "**Q6.** Let's explore multiple linear regression in a two-variable case, to build more intuition about what is happening.\n",
        "\n",
        "Suppose the model is \n",
        "$$\n",
        "\\hat{y}_i = b_0 + b_1 z_{i1} + b_2 z_{i2}\n",
        "$$\n",
        "Assume that $z_{ij}$ is centered or de-meaned, so that $z_{ij} = x_{ij} - m_j$ where $m_j$ is the mean of variable $j$ and $x_{ij}$ is the original value of variable $j$ for observation $i$. Notice that this implies\n",
        "$$\n",
        "\\dfrac{1}{N} \\sum_{i=1}^N z_{ij} = 0\n",
        "$$\n",
        "which will simplify your calculations below substantially!\n",
        "\n",
        "1. Write down the SSE for this model.\n",
        "2. Take partial derivatives with respect to $b_0$, $b_1$, and $b_2$.\n",
        "3. Verify that the average error is zero and $e \\cdot z =0$ at the optimum, just as in the single linear regression case.\n",
        "4. Show that the optimal intercept is $b_0^* = \\bar{y}$. Eliminate $b_0^*$ from the remaining equations, and focus on $b_1$ and $b_2$.\n",
        "5. Write your results as a matrix equation in the form \"$Ab=C$\". These are called the **normal equations**.\n",
        "6. Divide both sides by $N$ and substitute $z_{ij} = x_{ij} - m_j$ back into your normal equations for $x_{ij}$. What is the matrix $A$? What is the vector $C$? Explain the intuition of your discovery."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "547d5828",
      "metadata": {},
      "source": [
        "**Q7.** In class, we showed that for the single linear regression model,\n",
        "\\begin{alignat*}{3}\n",
        "a^* &=& \\bar{y} \\\\\n",
        "b^* &=& \\dfrac{\\sum_{i=1}^N(y_i - \\bar{y})(x_i-\\bar{x})}{\\sum_{i=1}^N (x_i-\\bar{x})^2},\n",
        "\\end{alignat*}\n",
        "\n",
        "1. When will $b^*$ be large or small, depending on the relationship between $X$ and $Y$ and the variance of $X$?\n",
        "2. Suppose you have measurement error in $X$ which artificially inflates its variance (e.g. bad data cleaning). We'll model this as saying the \"real\" value of $X$ for observation $i$ is $z_i$, but we observe $x_i = z_i + n_i$, where $n_i$ is the added noise. Does this affect the intercept of the regression? What happens to the $b^*$ coefficient relative to a noise-less model? How will affect your ability to predict? (This phenomenon is called **attenuation**.) \n",
        "3. Suppose the noise $n_i$ is independent of $z_i$ and $y_i$, so that (approximately)\n",
        "$$\n",
        "\\dfrac{1}{N} \\sum_{i=1}^N (y_i - \\bar{y})(n_i - \\bar{n}) =0, \\quad \\dfrac{1}{N} \\sum_{i=1}^N (z_i - \\bar{z})(n_i - \\bar{n}) =0.\n",
        "$$\n",
        "and that the mean of the bias is zero, so that\n",
        "$$\n",
        "\\dfrac{1}{N} \\sum_{i=1}^N n_i = 0.\n",
        "$$\n",
        "In this case, the noise $n_i$ is zero on average and independent of the values of $x_i$ and $y_i$: It's just measurement error or lazy data cleaning.\n",
        "Explain the intuition of your result. \n",
        "\n",
        "4. How does attenuation factor into the cost-benefit analysis of gathering higher quality data or cleaning it more carefully?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b67478ac-ad78-4a44-9720-583c71b8da14",
      "metadata": {
        "id": "b67478ac-ad78-4a44-9720-583c71b8da14"
      },
      "source": [
        "**Q8.**\n",
        "1. Find a dataset on a topic you're interested in. Some easy options are data.gov, kaggle.com, and data.world.\n",
        "2. Clean the data and do some exploratory data analysis on key variables that interest you. Pick a particular target/outcome variable and features/predictors.\n",
        "3. Split the sample into an ~80% training set and a ~20% test set.\n",
        "4. Run a few regressions of your target/outcome variable on a variety of features/predictors. Compute the SSE on the test set.\n",
        "5. Which model performed the best, and why?\n",
        "6. What did you learn?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcf48562",
      "metadata": {},
      "source": [
        "**Q9.** There is a folder called `heart_failure` which contains reasonably detailed health data on patients and whether they die of congestive heart failure. \n",
        "\n",
        "1. Load the data and perform an 80/20-train/test split.\n",
        "2. Using dummy/one-hot-encoded variables and transformations of the numeric features, build the best model you can. **But**, do not delete code chunks or revise your work substantially as you experiment. Just keep moving forward with your ideas and experiments.\n",
        "3. When you're done, scroll through your notebook. What worked and what didn't? Does your code have intention, or are you randomly experimenting? If you had to do this again, what might you do differently to get to a good model faster?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0125d03b",
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "source": [
        "**Q10.** Let's look at a cousin of Linear Regression, called **kernel regression** or **local constant least squares** or **Nadaraya-Watson Estimator**.\n",
        "\n",
        "We derived the OLS estimator for single linear regression by minimizing\n",
        "$$\n",
        "SSE(b_0, b_1) = \\frac{1}{N}\\sum_{i=1}^N (y_i - b_0 - b_1 x_i)^2\n",
        "$$\n",
        "with solution\n",
        "$$\n",
        "\\hat{b}_0 = \\bar{y} - \\hat{b}_1 \\bar{x}, \\quad \\hat{b}_1 = \\dfrac{\\frac{1}{N} \\sum_{i=1}^N (x_i-\\bar{x})(y_i - \\bar{y})}{s_x^2}.\n",
        "$$\n",
        "\n",
        "When you step back and think about it, this is a bit weird: The algorithm is computing sample means, variances, and covariances, and using those to create a predictive model. The data themselves arguably vanish from the solution. This is elegant, this is strange.\n",
        "\n",
        "Instead, let $k(z)$ be a kernel function, such as the Gaussian\n",
        "$$\n",
        "k(z) = \\frac{1}{\\sqrt{2\\pi}} e^{-z^2/2}\n",
        "$$\n",
        "or uniform\n",
        "$$\n",
        "k(z) = \\begin{cases}\n",
        "1/2, & |z| \\le \\frac{1}{2}\\\\\n",
        "0, & \\text{otherwise.}\n",
        "\\end{cases}\n",
        "$$\n",
        "We'll instead minimize, or each predictor value $x$,\n",
        "$$\n",
        "SSE(\\hat{y}(x)) = \\dfrac{1}{N} \\sum_{i=1}^N \\left\\lbrace y_i - \\hat{y}(x)\\right\\rbrace^2 \\dfrac{1}{h} k \\left( \\dfrac{x-x_i}{h} \\right).\n",
        "$$\n",
        "\n",
        "1. Show that the optimal predictor is\n",
        "$$\n",
        "\\hat{y}(x) = \\dfrac{ \\frac{1}{Nh} \\sum_{i=1}^N  y_i k \\left( \\dfrac{x-x_i}{h} \\right) }{\\frac{1}{Nh} \\sum_{i=1}^N k \\left(  \\dfrac{x-x_i}{h} \\right)}\n",
        "$$\n",
        "This has many names, but let's call it the local constant least squares (LCLS) estimator, as opposed to ordinary least squares (OLS).\n",
        "\n",
        "2. Compare and contrast LCLS with both OLS and $k$-Nearest Neighbor as a regression algorithm. \n",
        "\n",
        "3. Write a function or class that implements the LCLS estimator for a single predictor variable $x$. For a default bandwidth $h$, you can use the maximum of the Silverman plug-ins for estimating kernel densities for $X$ and $Y$:\n",
        "$$\n",
        "h_y = 1.06 \\times s_y^{-1/5}, \\quad h_x = 1.06 \\times s_x^{-1/5},\n",
        "$$\n",
        "$$\n",
        "h = \\max \\{ h_y, h_x \\}.\n",
        "$$\n",
        "For the kernel, you can hard-code the uniform, Gaussian, or Epanechnikov, or make it a parameter the user can adjust with a default choice.\n",
        "\n",
        "4. For one of the datasets available for the homework, use your LCLS estimator from part 3 to predict values $\\hat{y}(x_i)$ for each datapoint $x_i$. Plot your estimator $\\hat{y}$ as a line over a scatterplot of the data $\\{(x_i,y_i)\\}_{i=1}^N$. Tune the bandwidth until you \n",
        "\n",
        "5. Conceptually, how would you extend this analysis to a vector of predictors, $x = (x_1, ..., x_L)$ instead of just one explanatory variable $x$?\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
